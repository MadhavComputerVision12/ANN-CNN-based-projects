{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1AifJOFK-U4RZNbBylra9Nrp4DWs0ZIwp","authorship_tag":"ABX9TyPDgxHg5K4WzN2/qP4RCDMm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"np-ti2VupulH"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import keras\n","from google.colab import files"]},{"cell_type":"code","source":["from PIL import Image\n","import os\n","image_dir = '/content/drive/MyDrive/brain tumor/yes'\n","image_files = os.listdir(image_dir)\n","\n","yes = []\n","\n","for file in image_files:\n","    image_path = os.path.join(image_dir, file)\n","    image = Image.open(image_path)\n","    yes.append(image)\n","yes[0].show()"],"metadata":{"id":"nL51UnREqrai"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import os\n","\n","\n","image_dir = '/content/drive/MyDrive/brain tumor/no'\n","\n","\n","image_files = os.listdir(image_dir)\n","\n","no = []\n","\n","for file in image_files:\n","    image_path = os.path.join(image_dir, file)\n","    image = Image.open(image_path)\n","    no.append(image)\n","\n","no[0].show()\n"],"metadata":{"id":"VrrCnTtjr1iA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#now we have stored the yes and no in form of a list\n","#like yes[], no[] now we see properties\n","print(len(yes))\n","print(len(no))"],"metadata":{"id":"IaQkv8Iostqu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["yes_train=yes[:108]\n","yes_test=yes[108:]\n","no_train=no[:69]\n","no_test=no[69:]"],"metadata":{"id":"xQ9ar5iYtDJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#one hot vector encoding\n","from keras.utils import to_categorical\n","yes_train_labels=[1]*108\n","no_train_labels=[0]*69\n","yes_test_labels=[1]*47\n","no_test_labels=[0]*29"],"metadata":{"id":"1EKt8hHrteGJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#merging train labels and train pics into one dataset\n","#namely train and other namely test\n","train_labels=[]\n","train_labels.extend(yes_train_labels)\n","train_labels.extend(no_train_labels)\n","test_labels=[]\n","test_labels.extend(yes_test_labels)\n","test_labels.extend(no_test_labels)"],"metadata":{"id":"fuZ0-HZ8uhPO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def resize_images(images,x,y):\n","  resized_images=[]\n","  for image in images:\n","    new_image = image.resize((x, y))\n","    resized_images.append(new_image)\n","  return resized_images"],"metadata":{"id":"qLqOYjoXzReT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images=[]\n","train_images.extend(yes_train)\n","train_images.extend(no_train)\n","test_images=[]\n","test_images.extend(yes_test)\n","test_images.extend(no_test)\n","train_images=resize_images(train_images,100,100)\n","test_images=resize_images(test_images,100,100)"],"metadata":{"id":"QpNzppKSv8Kj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["height, width = train_images[0].size\n","\n","# Print the dimensions\n","print(\"Width:\", width)\n","print(\"Height:\", height)\n","print(\"Channels:\", train_images[0].getbands())\n","\n","\n","height, width = test_images[0].size\n","\n","# Print the dimensions\n","print(\"Width:\", width)\n","print(\"Height:\", height)\n","print(\"Channels:\", test_images[0].getbands())"],"metadata":{"id":"U1uajQJ81m7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#the output tells that there are three channels\n","#RGB is this indication"],"metadata":{"id":"zXyZnqBT2ygV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The output tells us that there are in total 3 channels RGB\n","Now we have preproccessed out data to meet the criteria\n","Now it is fit to train\n","Now main question is howcome the blck and white grayscale images are showing this RGB?"],"metadata":{"id":"5fw37ukU25w9"}},{"cell_type":"code","source":["#finally we have preproccessed our data\n","#now our task is to implement a model\n","# I will first import all the needed packages then start\n","from keras.models import Sequential\n","from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense"],"metadata":{"id":"jB30p5a-xUnE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resized_train_images = [img.resize((100, 100)).convert('RGB') for img in train_images]\n","resized_test_images = [img.resize((100, 100)).convert('RGB') for img in test_images]\n","\n","# Convert resized images to NumPy arrays\n","train_images = np.asarray([np.array(img) for img in resized_train_images])\n","test_images = np.asarray([np.array(img) for img in resized_test_images])\n","\n","# Convert data type and normalize pixel values\n","train_images = train_images.astype('float32') / 255.0\n","test_images = test_images.astype('float32') / 255.0"],"metadata":{"id":"jgu5omSe-NSO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Resized train image shapes:\")\n","for img in resized_train_images:\n","    print(np.array(img).shape)\n","\n","print(\"Resized test image shapes:\")\n","for img in resized_test_images:\n","    print(np.array(img).shape)\n"],"metadata":{"id":"7W7HJ6h--4jV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras import layers, models\n","\n","# Load the pre-trained VGG16 model without the top classification layers\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n","\n","# Freeze the feature extraction layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Create your old model or load it from a saved file\n","# Replace this with your own model architecture and weights\n","model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='sigmoid')\n","    # Add layers from your old model here\n","])"],"metadata":{"id":"Pubpd_riycuk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compiling the model\n","model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"],"metadata":{"id":"l7H8Hxmlyntb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#now we fir the model\n","model.fit(train_images, to_categorical(train_labels), batch_size=32, epochs=20, validation_data=(test_images, to_categorical(test_labels)))"],"metadata":{"id":"dS3gdtYcEsMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cRfGzCefvRlQ"},"execution_count":null,"outputs":[]}]}